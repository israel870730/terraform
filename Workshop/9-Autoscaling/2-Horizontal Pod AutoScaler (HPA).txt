Deploy the Metrics Server
The Metrics Server is a scalable, efficient source of container resource metrics for Kubernetes built-in auto scaling pipelines.

These metrics will drive the scaling behavior of the deployments . We will deploy the metrics server using Kubernetes Metrics Server .

The below deployment is the latest version of metrics server, but installation instructions for previous releases can be found in Metrics Server releases .

kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

Let's verify the status of the metrics-server APIService (This can take few minutes).
kubectl get apiservice v1beta1.metrics.k8s.io -o json | jq '.status'

{
  "conditions": [
    {
      "lastTransitionTime": "2020-11-10T06:39:13Z",
      "message": "all checks passed",
      "reason": "Passed",
      "status": "True",
      "type": "Available"
    }
  ]
}

Create a HPA resource for the proddetail Microservice

The HPA scales up when CPU exceeds 40% of the allocated container resource for proddetail service.
kubectl autoscale deployment proddetail -n workshop `#The target average CPU utilization` \
    --cpu-percent=40 \
    --min=1 `#The lower limit for the number of pods that can be set by the autoscaler` \
    --max=3 `#The upper limit for the number of pods that can be set by the autoscaler`

This should show the following output:

horizontalpodautoscaler.autoscaling/proddetail autoscaled

View the HPA using kubectl. You might see <unknown>/40% for 1-2 minutes and then you should be able to see 0%/40%
kubectl get hpa -n workshop

This should show the following output:

NAME         REFERENCE               TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
proddetail   Deployment/proddetail   1%/40%    1         3         1          35s

Generate load to trigger scaling

Open a New Terminal in the Cloud9 Environment and run the following command to drop into a shell on a new container:
kubectl run -i --tty load-generator --image=busybox /bin/sh

In the container bash, execute a loop to continuously call the /catalogDetail API:

while true; do wget -q -O - http://proddetail.workshop.svc.cluster.local:3000/catalogDetail; done

In the previous terminal, watch the HPA with the following command:

Scaling up may take a few minutes. You may need to wait to see the replicas scaling.
kubectl get hpa -n workshop -w

You will see the HPA scale the pods from 1, up to our configured maximum (3) until the CPU average is below our target (40%).

To see the "Pod Utilization Over Pod Limit" metrics in CloudWatch Container Insights, follow these steps:

In the AWS Console, go to CloudWatch -> Insights -> Container Insights and search for proddetail in the Resources list. There should be 2 results; click on proddetail of type EKS Pod.

In the Pod CPU Utilization widget, click on the menu (the 3 dots) and then click View in metrics.

You can see the CPU Utilization (Over Limit)

You can now stop (Ctrl + C) load test that was running in the other terminal. You will notice that HPA will slowly bring the replica count to min number based on its configuration. You should also get out of load testing application by pressing Ctrl + D.

Scaling down may take couple of minutes.

Clean up
kubectl delete -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
kubectl delete pod load-generator
kubectl delete hpa proddetail -n workshop